{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installation & Setup"
      ],
      "metadata": {
        "id": "w3mZ4Pcyw5wP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29O9fNlsPGDL",
        "outputId": "694b9f4a-aad4-450e-8488-7a2b1dafb67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-cpu\n",
            "  Downloading https://github.com/mlc-ai/package/releases/download/v0.9.dev0/mlc_ai_cpu-0.17.2-cp310-cp310-manylinux_2_28_x86_64.whl (185.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.8/185.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (3.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (1.13.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mlc-ai-cpu) (4.12.2)\n",
            "Installing collected packages: mlc-ai-cpu\n",
            "Successfully installed mlc-ai-cpu-0.17.2\n"
          ]
        }
      ],
      "source": [
        "!python3 -m  pip install mlc-ai-cpu -f https://mlc.ai/wheels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zHP3PYWYLMY",
        "outputId": "ecd7d076-0c54-4fe2-b2cd-b447f79166a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NCSU-CSC_591-RealTime_AI_and_Machine_Learning_Systems-CourseProject-LPRNet'...\n",
            "remote: Enumerating objects: 1027, done.\u001b[K\n",
            "remote: Counting objects: 100% (1027/1027), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1022/1022), done.\u001b[K\n",
            "remote: Total 1027 (delta 4), reused 1021 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1027/1027), 19.08 MiB | 23.69 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Yogesh31Hasabe/NCSU-CSC_591-RealTime_AI_and_Machine_Learning_Systems-CourseProject-LPRNet.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd NCSU-CSC_591-RealTime_AI_and_Machine_Learning_Systems-CourseProject-LPRNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1-Os9qb9cL1",
        "outputId": "224ee006-cd05-4a81-f5f0-cc09d41a5c9a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NCSU-CSC_591-RealTime_AI_and_Machine_Learning_Systems-CourseProject-LPRNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "import torch.nn as nn\n",
        "from tvm import relay\n",
        "from tvm.contrib.download import download_testdata\n",
        "from data.load_data import CHARS, CHARS_DICT, LPRDataLoader\n",
        "from torchvision.transforms import functional as TF\n",
        "from types import SimpleNamespace\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from model.LPRNet import build_lprnet\n",
        "from torch.autograd import Variable\n",
        "from tvm.contrib import graph_executor\n",
        "import torch.nn.functional as F\n",
        "import tvm.auto_scheduler as auto_scheduler\n",
        "from tvm.autotvm.tuner import XGBTuner\n",
        "from tvm import autotvm\n",
        "from torch.utils.data import *\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "HToN7PkjxYx2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model Accuracy"
      ],
      "metadata": {
        "id": "XqBtXW0kIjcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/NCSU-CSC_591-RealTime_AI_and_Machine_Learning_Systems-CourseProject-LPRNet/test_LPRNet.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP4kJ57CIngW",
        "outputId": "909b1bd4-dc1e-4479-8d5c-0cf17914a574"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful to build network!\n",
            "/content/NCSU-CSC_591-RealTime_AI_and_Machine_Learning_Systems-CourseProject-LPRNet/test_LPRNet.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(args.pretrained_model, map_location=torch.device('cpu')))\n",
            "load pretrained model successful!\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[Info] Test Accuracy: 0.902 [902:55:43:1000]\n",
            "[Info] Test Speed: 0.18756708931922914s 1/1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JIT Trace for NN Module"
      ],
      "metadata": {
        "id": "4Of_jrHp0sgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class small_basic_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(small_basic_block, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out // 4, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(3, 1), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out // 4, kernel_size=(1, 3), padding=(0, 1)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(ch_out // 4, ch_out, kernel_size=1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class LPRNet(nn.Module):\n",
        "    def __init__(self, lpr_max_len, phase, class_num, dropout_rate):\n",
        "        super(LPRNet, self).__init__()\n",
        "        self.phase = phase\n",
        "        self.lpr_max_len = lpr_max_len\n",
        "        self.class_num = class_num\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1), # 0\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),  # 2\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 1, 1)),\n",
        "            small_basic_block(ch_in=64, ch_out=128),    # *** 4 ***\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),  # 6\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 1, 2)),\n",
        "            small_basic_block(ch_in=64, ch_out=256),   # 8\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),  # 10\n",
        "            small_basic_block(ch_in=256, ch_out=256),   # *** 11 ***\n",
        "            nn.BatchNorm2d(num_features=256),   # 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(4, 1, 2)),  # 14\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=(1, 4), stride=1),  # 16\n",
        "            nn.BatchNorm2d(num_features=256),\n",
        "            nn.ReLU(),  # 18\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Conv2d(in_channels=256, out_channels=class_num, kernel_size=(13, 1), stride=1), # 20\n",
        "            nn.BatchNorm2d(num_features=class_num),\n",
        "            nn.ReLU(),  # *** 22 ***\n",
        "        )\n",
        "        self.container = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=448+self.class_num, out_channels=self.class_num, kernel_size=(1, 1), stride=(1, 1)),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        keep_features = list()\n",
        "        for i, layer in enumerate(self.backbone.children()):\n",
        "            x = layer(x)\n",
        "            if i in [2, 6, 13, 22]: # [2, 4, 8, 11, 22]\n",
        "                keep_features.append(x)\n",
        "\n",
        "        global_context = list()\n",
        "        for i, f in enumerate(keep_features):\n",
        "            if i in [0, 1]:\n",
        "                f = nn.AvgPool2d(kernel_size=5, stride=5)(f)\n",
        "            if i in [2]:\n",
        "                f = nn.AvgPool2d(kernel_size=(4, 10), stride=(4, 2))(f)\n",
        "            f_pow = torch.pow(f, 2)\n",
        "            f_mean = torch.mean(f_pow)\n",
        "            f = torch.div(f, f_mean)\n",
        "            global_context.append(f)\n",
        "\n",
        "        x = torch.cat(global_context, 1)\n",
        "        x = self.container(x)\n",
        "        logits = torch.mean(x, dim=2)\n",
        "\n",
        "        return logits\n",
        "\n",
        "def build_lprnet(lpr_max_len=8, phase=False, class_num=66, dropout_rate=0.5):\n",
        "\n",
        "    Net = LPRNet(lpr_max_len, phase, class_num, dropout_rate)\n",
        "\n",
        "    if phase == \"train\":\n",
        "        return Net.train()\n",
        "    else:\n",
        "        return Net.eval()"
      ],
      "metadata": {
        "id": "qfjqJuDA1L2h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lprnet = build_lprnet(lpr_max_len=8, phase=False, class_num=68, dropout_rate=0.5)\n",
        "lprnet.load_state_dict(torch.load(\"./weights/Final_LPRNet_model.pth\",  map_location=torch.device('cpu')))\n",
        "lprnet.eval()\n",
        "\n",
        "example_input = torch.randn(1, 3, 24, 94)\n",
        "lprnet_traced_model = torch.jit.trace(lprnet, example_input)\n",
        "lprnet_traced_model.save(\"./weights/lprnet_mlc_optimization.pt\")\n",
        "\n",
        "# Load the TorchScript model\n",
        "scripted_model = torch.jit.load(\"./weights/lprnet_mlc_optimization.pt\")\n",
        "scripted_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmLxo3v81ZpX",
        "outputId": "5d93e9fc-51b3-4fd6-dc5e-a2487a59a17d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-92057476a371>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  lprnet.load_state_dict(torch.load(\"./weights/Final_LPRNet_model.pth\",  map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RecursiveScriptModule(\n",
              "  original_name=LPRNet\n",
              "  (backbone): RecursiveScriptModule(\n",
              "    original_name=Sequential\n",
              "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
              "    (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "    (2): RecursiveScriptModule(original_name=ReLU)\n",
              "    (3): RecursiveScriptModule(original_name=MaxPool3d)\n",
              "    (4): RecursiveScriptModule(\n",
              "      original_name=small_basic_block\n",
              "      (block): RecursiveScriptModule(\n",
              "        original_name=Sequential\n",
              "        (0): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (1): RecursiveScriptModule(original_name=ReLU)\n",
              "        (2): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (3): RecursiveScriptModule(original_name=ReLU)\n",
              "        (4): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (5): RecursiveScriptModule(original_name=ReLU)\n",
              "        (6): RecursiveScriptModule(original_name=Conv2d)\n",
              "      )\n",
              "    )\n",
              "    (5): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "    (6): RecursiveScriptModule(original_name=ReLU)\n",
              "    (7): RecursiveScriptModule(original_name=MaxPool3d)\n",
              "    (8): RecursiveScriptModule(\n",
              "      original_name=small_basic_block\n",
              "      (block): RecursiveScriptModule(\n",
              "        original_name=Sequential\n",
              "        (0): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (1): RecursiveScriptModule(original_name=ReLU)\n",
              "        (2): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (3): RecursiveScriptModule(original_name=ReLU)\n",
              "        (4): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (5): RecursiveScriptModule(original_name=ReLU)\n",
              "        (6): RecursiveScriptModule(original_name=Conv2d)\n",
              "      )\n",
              "    )\n",
              "    (9): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "    (10): RecursiveScriptModule(original_name=ReLU)\n",
              "    (11): RecursiveScriptModule(\n",
              "      original_name=small_basic_block\n",
              "      (block): RecursiveScriptModule(\n",
              "        original_name=Sequential\n",
              "        (0): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (1): RecursiveScriptModule(original_name=ReLU)\n",
              "        (2): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (3): RecursiveScriptModule(original_name=ReLU)\n",
              "        (4): RecursiveScriptModule(original_name=Conv2d)\n",
              "        (5): RecursiveScriptModule(original_name=ReLU)\n",
              "        (6): RecursiveScriptModule(original_name=Conv2d)\n",
              "      )\n",
              "    )\n",
              "    (12): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "    (13): RecursiveScriptModule(original_name=ReLU)\n",
              "    (14): RecursiveScriptModule(original_name=MaxPool3d)\n",
              "    (15): RecursiveScriptModule(original_name=Dropout)\n",
              "    (16): RecursiveScriptModule(original_name=Conv2d)\n",
              "    (17): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "    (18): RecursiveScriptModule(original_name=ReLU)\n",
              "    (19): RecursiveScriptModule(original_name=Dropout)\n",
              "    (20): RecursiveScriptModule(original_name=Conv2d)\n",
              "    (21): RecursiveScriptModule(original_name=BatchNorm2d)\n",
              "    (22): RecursiveScriptModule(original_name=ReLU)\n",
              "  )\n",
              "  (container): RecursiveScriptModule(\n",
              "    original_name=Sequential\n",
              "    (0): RecursiveScriptModule(original_name=Conv2d)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile into Relay Module"
      ],
      "metadata": {
        "id": "VbxRSqY511wK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'img_size': [94, 24],\n",
        "    'test_img_dirs': \"./data/test\",\n",
        "    'dropout_rate': 0,\n",
        "    'lpr_max_len': 8,\n",
        "    'test_batch_size': 100,\n",
        "    'phase_train': False,\n",
        "    'num_workers': 2,\n",
        "    'cuda': False,\n",
        "    'show': False,\n",
        "    'pretrained_model': './weights/Final_LPRNet_model.pth'\n",
        "}\n",
        "\n",
        "args = SimpleNamespace(**args)"
      ],
      "metadata": {
        "id": "iRbPK8p21abZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (args.test_batch_size, 3, 24, 94)\n",
        "input_name = \"input0\"\n",
        "input_shapes = [(input_name, input_shape)]\n",
        "\n",
        "# Convert to TVM Relay format\n",
        "mod, params = relay.frontend.from_pytorch(scripted_model, input_shapes)\n",
        "\n",
        "# Define the target device\n",
        "target = \"llvm\"\n",
        "dev = tvm.cuda(0) if target == \"cuda\" else tvm.cpu()\n",
        "\n",
        "# Compile the model\n",
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod, target=target, params=params)\n",
        "\n",
        "\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_LjTSCa2Kor",
        "outputId": "82d077cc-809e-40f8-bbac-86fa47d1db5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autotvm:One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Function - 1 : Accuracy & Speed"
      ],
      "metadata": {
        "id": "sUhg7k9-2lMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    lengths = []\n",
        "    for _, sample in enumerate(batch):\n",
        "        img, label, length = sample\n",
        "        imgs.append(torch.from_numpy(img))\n",
        "        labels.extend(label)\n",
        "        lengths.append(length)\n",
        "    labels = np.asarray(labels).flatten().astype(np.float32)\n",
        "\n",
        "    return (torch.stack(imgs, 0), torch.from_numpy(labels), lengths)\n",
        "\n",
        "def test(module):\n",
        "    test_img_dirs = os.path.expanduser(args.test_img_dirs)\n",
        "    test_dataset = LPRDataLoader(test_img_dirs.split(','), args.img_size, args.lpr_max_len)\n",
        "    Greedy_Decode_Eval(module, test_dataset, args)\n",
        "\n",
        "def Greedy_Decode_Eval(module, datasets, args):\n",
        "    # TestNet = Net.eval()\n",
        "    epoch_size = len(datasets) // args.test_batch_size\n",
        "    batch_iterator = iter(DataLoader(datasets, args.test_batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn))\n",
        "\n",
        "    Tp = 0\n",
        "    Tn_1 = 0\n",
        "    Tn_2 = 0\n",
        "    t1 = time.time()\n",
        "    for i in range(epoch_size):\n",
        "        # load train data\n",
        "        images, labels, lengths = next(batch_iterator)\n",
        "        start = 0\n",
        "        targets = []\n",
        "        for length in lengths:\n",
        "            label = labels[start:start+length]\n",
        "            targets.append(label)\n",
        "            start += length\n",
        "        targets = np.array([el.numpy() for el in targets])\n",
        "        imgs = images.numpy().copy()\n",
        "\n",
        "        if args.cuda:\n",
        "            images = Variable(images.cuda())\n",
        "        else:\n",
        "            images = Variable(images)\n",
        "\n",
        "        # forward\n",
        "        # prebs = Net(images)\n",
        "        # Set input and run\n",
        "        module.set_input(input_name, tvm.nd.array(images.numpy()))\n",
        "        module.run()\n",
        "\n",
        "        # Get output\n",
        "        tvm_output = module.get_output(0).asnumpy()\n",
        "        print(\"Output shape:\", tvm_output.shape)\n",
        "        prebs = tvm_output\n",
        "        # greedy decode\n",
        "        # prebs = prebs.cpu().detach().numpy()\n",
        "        preb_labels = list()\n",
        "        for i in range(prebs.shape[0]):\n",
        "            preb = prebs[i, :, :]\n",
        "            preb_label = list()\n",
        "            for j in range(preb.shape[1]):\n",
        "                preb_label.append(np.argmax(preb[:, j], axis=0))\n",
        "            no_repeat_blank_label = list()\n",
        "            pre_c = preb_label[0]\n",
        "            if pre_c != len(CHARS) - 1:\n",
        "                no_repeat_blank_label.append(pre_c)\n",
        "            for c in preb_label: # dropout repeate label and blank label\n",
        "                if (pre_c == c) or (c == len(CHARS) - 1):\n",
        "                    if c == len(CHARS) - 1:\n",
        "                        pre_c = c\n",
        "                    continue\n",
        "                no_repeat_blank_label.append(c)\n",
        "                pre_c = c\n",
        "            preb_labels.append(no_repeat_blank_label)\n",
        "        for i, label in enumerate(preb_labels):\n",
        "            # show image and its predict label\n",
        "            # if args.show:\n",
        "                # show(imgs[i], label, targets[i])\n",
        "            if len(label) != len(targets[i]):\n",
        "                Tn_1 += 1\n",
        "                continue\n",
        "            if (np.asarray(targets[i]) == np.asarray(label)).all():\n",
        "                Tp += 1\n",
        "            else:\n",
        "                Tn_2 += 1\n",
        "    Acc = Tp * 1.0 / (Tp + Tn_1 + Tn_2)\n",
        "    print(\"[Info] Test Accuracy: {} [{}:{}:{}:{}]\".format(Acc, Tp, Tn_1, Tn_2, (Tp+Tn_1+Tn_2)))\n",
        "    t2 = time.time()\n",
        "    print(\"[Info] Test Speed: {}s 1/{}]\".format((t2 - t1) / len(datasets), len(datasets)))"
      ],
      "metadata": {
        "id": "3DQwjh3T2nvg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLC Optimization: Manual Optimization"
      ],
      "metadata": {
        "id": "COz5yEJS2s0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Canonicalization and Simplification\n",
        "mod_manual = relay.transform.InferType()(mod)\n",
        "mod_manual = relay.transform.SimplifyInference()(mod_manual)\n",
        "mod_manual = relay.transform.CanonicalizeOps()(mod_manual)\n",
        "\n",
        "# 2. Basic Arithmetic Simplification\n",
        "mod_manual = relay.transform.FoldConstant()(mod_manual)\n",
        "mod_manual = relay.transform.CombineParallelConv2D()(mod_manual)\n",
        "\n",
        "# 3. Layout Transformation (if applicable)\n",
        "# This can help optimize convolution and other spatial operations\n",
        "mod_manual = relay.transform.AlterOpLayout()(mod_manual)\n",
        "\n",
        "# 4. Dead Code Elimination\n",
        "mod_manual = relay.transform.DeadCodeElimination()(mod_manual)\n",
        "\n",
        "# 5. Optimize memory usage\n",
        "mod_manual = relay.transform.EliminateCommonSubexpr()(mod_manual)"
      ],
      "metadata": {
        "id": "-pDTzz9k26bG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target device\n",
        "target = \"llvm\"\n",
        "dev = tvm.cuda(0) if target == \"cuda\" else tvm.cpu()\n",
        "\n",
        "# Compile the model\n",
        "with tvm.transform.PassContext(opt_level=3):\n",
        "    lib = relay.build(mod_manual, target=target, params=params)\n",
        "\n",
        "# Create a graph executor\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
        "print('Testing the model after manual optimization \\n')\n",
        "test(module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r79EYrsM3DIz",
        "outputId": "24024466-91ef-452b-9643-0177960e99f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after manual optimization \n",
            "\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "[Info] Test Accuracy: 0.899 [899:61:40:1000]\n",
            "[Info] Test Speed: 0.03605321073532104s 1/1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLC Optimization: Auto-Tuning Optimization"
      ],
      "metadata": {
        "id": "zEELIriO3OlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number = 10\n",
        "repeat = 1\n",
        "min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
        "timeout = 10  # in seconds\n",
        "\n",
        "# create a TVM runner\n",
        "runner = autotvm.LocalRunner(\n",
        "    number=number,\n",
        "    repeat=repeat,\n",
        "    timeout=timeout,\n",
        "    min_repeat_ms=min_repeat_ms,\n",
        "    enable_cpu_cache_flush=True,\n",
        ")"
      ],
      "metadata": {
        "id": "fzy3WnJG3RJg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_option = {\n",
        "    \"tuner\": \"xgb\",\n",
        "    \"trials\": 20,\n",
        "    \"early_stopping\": 100,\n",
        "    \"measure_option\": autotvm.measure_option(\n",
        "        builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
        "    ),\n",
        "    \"tuning_records\": \"lprnet-autotuning.json\",\n",
        "}\n",
        "\n",
        "# begin by extracting the tasks from the onnx model\n",
        "tasks = autotvm.task.extract_from_program(mod[\"main\"], target=target, params=params)\n",
        "\n",
        "# Tune the extracted tasks sequentially.\n",
        "for i, task in enumerate(tasks):\n",
        "    prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
        "\n",
        "    # choose tuner\n",
        "    tuner = \"xgb\"\n",
        "\n",
        "    # create tuner\n",
        "    if tuner == \"xgb\":\n",
        "        tuner_obj = XGBTuner(task, loss_type=\"reg\")\n",
        "    else:\n",
        "        raise ValueError(\"Invalid tuner: \" + tuner)\n",
        "\n",
        "    tuner_obj.tune(\n",
        "        n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
        "        early_stopping=tuning_option[\"early_stopping\"],\n",
        "        measure_option=tuning_option[\"measure_option\"],\n",
        "        callbacks=[\n",
        "            autotvm.callback.progress_bar(tuning_option[\"trials\"], prefix=prefix),\n",
        "            autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYvz4pMI3vTx",
        "outputId": "5c2c14ad-7ca2-48d1-f28f-764e9dc791af"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Task  1/13]  Current/Best:    3.18/  16.42 GFLOPS | Progress: (20/20) | 54.26 s Done.\n",
            "[Task  2/13]  Current/Best:   13.89/  18.15 GFLOPS | Progress: (20/20) | 55.05 s Done.\n",
            "[Task  3/13]  Current/Best:   12.41/  15.34 GFLOPS | Progress: (20/20) | 55.97 s Done.\n",
            "[Task  4/13]  Current/Best:   18.36/  18.36 GFLOPS | Progress: (20/20) | 58.21 s Done.\n",
            "[Task  5/13]  Current/Best:    9.60/  12.91 GFLOPS | Progress: (20/20) | 97.45 s Done.\n",
            "[Task  6/13]  Current/Best:    5.63/  12.28 GFLOPS | Progress: (20/20) | 41.71 s Done.\n",
            "[Task  7/13]  Current/Best:   12.51/  15.32 GFLOPS | Progress: (20/20) | 83.31 s Done.\n",
            "[Task  8/13]  Current/Best:   14.20/  19.55 GFLOPS | Progress: (20/20) | 78.59 s Done.\n",
            "[Task  9/13]  Current/Best:    6.97/  16.60 GFLOPS | Progress: (20/20) | 112.39 s Done.\n",
            "[Task 10/13]  Current/Best:   11.37/  19.29 GFLOPS | Progress: (20/20) | 100.59 s Done.\n",
            "[Task 11/13]  Current/Best:    5.43/  19.75 GFLOPS | Progress: (20/20) | 117.34 s Done.\n",
            "[Task 12/13]  Current/Best:    0.00/  11.06 GFLOPS | Progress: (20/20) | 191.67 s Done.\n",
            "[Task 13/13]  Current/Best:   16.41/  16.41 GFLOPS | Progress: (20/20) | 46.59 s Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with autotvm.apply_history_best(tuning_option[\"tuning_records\"]):\n",
        "    with tvm.transform.PassContext(opt_level=3, config={}):\n",
        "        lib = relay.build(mod, target=target, params=params)\n",
        "\n",
        "dev = tvm.device(str(target), 0)\n",
        "module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
        "print('Testing the model after auto optimization \\n')\n",
        "test(module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHSkhZAh4RKY",
        "outputId": "4c2562af-3286-44b5-aca7-0bff1cd36d05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after auto optimization \n",
            "\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "Output shape: (100, 68, 18)\n",
            "[Info] Test Accuracy: 0.898 [898:61:41:1000]\n",
            "[Info] Test Speed: 0.0310540030002594s 1/1000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Module"
      ],
      "metadata": {
        "id": "SNu3AMKguIoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the module (includes weights/parameters)\n",
        "module_path = \"module.tar\"\n",
        "lib.export_library(module_path)\n",
        "print(f\"Module saved to {module_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS8BZ87945ks",
        "outputId": "a5f63688-4259-4c89-c19f-9fd249dc60e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module saved to module.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Function - 2 : Size"
      ],
      "metadata": {
        "id": "f_x1ar91-prI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Save the model temporarily to measure its size on disk and print the size.\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model to evaluate.\n",
        "        model_name (str): Name of the model for reference in output.\n",
        "    \"\"\"\n",
        "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "    model_size_kb = os.path.getsize(\"temp_delme.p\") / 1e3\n",
        "    print(f\"{model_name} Size (KB): {model_size_kb:.2f}\")\n",
        "    os.remove(\"temp_delme.p\")"
      ],
      "metadata": {
        "id": "S4p7U_-m-sq2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_module(module_path, module_name=\"Module\"):\n",
        "    if os.path.exists(module_path):\n",
        "        module_size_kb = os.path.getsize(module_path) / 1e3  # Size in KB\n",
        "        print(f\"{module_name} Size (KB): {module_size_kb:.2f}\")\n",
        "    else:\n",
        "        print(f\"{module_name} not found at {module_path}\")\n"
      ],
      "metadata": {
        "id": "Dlz8qtxVAmyw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of the model before MLC Optimization:')\n",
        "print_size_of_model(lprnet, model_name=\"Original Model\")\n",
        "print(\"\\n\")\n",
        "\n",
        "print('Size of the MLC Optimized Module:')\n",
        "module_path = \"./module.tar\"\n",
        "print_size_of_module(module_path, module_name=\"TVM Optimized Module\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_RReJbT__sq",
        "outputId": "238921d1-8e96-4146-fa16-9a6221b7e1c7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model before MLC Optimization:\n",
            "Original Model Size (KB): 1816.74\n",
            "\n",
            "\n",
            "Size of the MLC Optimized Module:\n",
            "TVM Optimized Module Size (KB): 840.69\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sUhg7k9-2lMp",
        "COz5yEJS2s0o",
        "zEELIriO3OlZ",
        "SNu3AMKguIoY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}